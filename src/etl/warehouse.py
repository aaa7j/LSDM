"""Helpers to register GLOBAL_* views from a Parquet warehouse.

This avoids loading CSV at runtime: the application should depend on
materialized Parquet datasets generated by the ETL (scripts/run_gav.py).
"""

from __future__ import annotations

import os
from typing import Dict, Iterable, List, Optional

from pyspark.sql import SparkSession


# Default mapping view -> subfolder name (lowercase)
GLOBAL_PARQUET: Dict[str, str] = {
    "GLOBAL_PLAYER": "global_player",
    "GLOBAL_TEAM": "global_team",
    "GLOBAL_GAME": "global_game",
    "GLOBAL_PLAY_BY_PLAY": "global_play_by_play",
    "GLOBAL_LINE_SCORE": "global_line_score",
    "GLOBAL_OTHER_STATS": "global_other_stats",
    "GLOBAL_OFFICIAL": "global_official",
    "GLOBAL_GAME_OFFICIAL": "global_game_official",
    "GLOBAL_DRAFT_COMBINE": "global_draft_combine",
    "GLOBAL_DRAFT_HISTORY": "global_draft_history",
    # Derived analytics when saved by ETL
    "GLOBAL_SCORING_EVENTS": "global_scoring_events",
    "GLOBAL_PLAYER_GAME_OFFENSE": "global_player_game_offense",
}


def register_from_warehouse(
    spark: SparkSession,
    base_dir: str = "warehouse",
    views: Optional[Iterable[str]] = None,
    cache: bool = True,
) -> List[str]:
    """Register Parquet datasets in ``base_dir`` as temp views.

    Returns the list of views successfully registered.
    Raises SystemExit if a requested view is missing.
    """
    base = os.fspath(base_dir)
    mapping = {k: GLOBAL_PARQUET[k] for k in (views or GLOBAL_PARQUET.keys())}
    registered: List[str] = []

    for view_name, sub in mapping.items():
        path = os.path.join(base, sub)
        if not os.path.isdir(path):
            raise SystemExit(f"Missing Parquet path: {path}")
        spark.read.parquet(path).createOrReplaceTempView(view_name)
        if cache:
            try:
                spark.catalog.cacheTable(view_name)
            except Exception:
                pass
        registered.append(view_name)
    return registered

